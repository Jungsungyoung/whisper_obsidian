# MeetScribe Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** íšŒì˜ ë…¹ìŒ íŒŒì¼(mp3/wav/m4a)ì„ FastAPI ì›¹ UIë¡œ ì—…ë¡œë“œí•˜ë©´ Whisperë¡œ ì „ì‚¬í•˜ê³  GPT-4o-minië¡œ ë¶„ì„í•´, ê¸°ì¡´ Obsidian Vaultì˜ 13_Meetings í´ë”ì— [íšŒì˜]/[ì „ì‚¬] ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ë¥¼ ìë™ ìƒì„±í•œë‹¤.

**Architecture:** FastAPI ë°±ì—”ë“œê°€ íŒŒì¼ ì—…ë¡œë“œë¥¼ ë°›ì•„ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì²˜ë¦¬í•œë‹¤. pyannote.audioê°€ í™”ìë¥¼ ë¶„ë¦¬í•˜ê³  Whisper(ë¡œì»¬ ìš°ì„  â†’ OpenAI API í´ë°±)ê°€ ì „ì‚¬í•œë‹¤. GPT-4o-miniê°€ ëª©ì /ì£¼ìš”ë…¼ì˜/ê²°ì •ì‚¬í•­/ì•¡ì…˜ì•„ì´í…œì„ ì¶”ì¶œí•˜ê³  ê¸°ì¡´ Meeting Note í…œí”Œë¦¿ê³¼ í˜¸í™˜ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ì„ ìƒì„±í•´ Vaultì— ì§ì ‘ ì €ì¥í•œë‹¤.

**Tech Stack:** Python 3.10+, FastAPI, openai-whisper, pyannote.audio, openai, pathlib, uvicorn

---

## ì‚¬ì „ ì¤€ë¹„ (ì½”ë“œ ì‘ì„± ì „)

### HuggingFace í† í° ì„¤ì • (í™”ì ë¶„ë¦¬ìš©)
1. https://huggingface.co ê³„ì • ìƒì„±
2. https://hf.co/pyannote/speaker-diarization-3.1 â†’ Accept License
3. https://hf.co/pyannote/segmentation-3.0 â†’ Accept License
4. https://hf.co/settings/tokens â†’ Access Token ìƒì„± (Read)
5. í† í°ì„ `.env` íŒŒì¼ì— ì €ì¥ (Task 1ì—ì„œ ì„¤ì •)

---

## Task 1: í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •

**Files:**
- Create: `meetscribe/requirements.txt`
- Create: `meetscribe/.env.example`
- Create: `meetscribe/config.py`
- Create: `meetscribe/tests/__init__.py`

**Step 1: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±**

```bash
mkdir -p meetscribe/pipeline
mkdir -p meetscribe/static
mkdir -p meetscribe/tests
mkdir -p meetscribe/uploads
```

**Step 2: `meetscribe/requirements.txt` ì‘ì„±**

```
fastapi==0.115.0
uvicorn[standard]==0.30.0
python-multipart==0.0.9
openai-whisper==20240930
openai==1.40.0
pyannote.audio==3.3.2
python-dotenv==1.0.1
torch>=2.0.0
torchaudio>=2.0.0
```

**Step 3: `meetscribe/.env.example` ì‘ì„±**

```
OPENAI_API_KEY=sk-...
HF_TOKEN=hf_...
WHISPER_MODEL=base
LLM_MODEL=gpt-4o-mini
VAULT_PATH=C:\Users\Admin\OneDrive\ë¬¸ì„œ\Obsidian Vault
MEETINGS_FOLDER=10_Calendar/13_Meetings
```

**Step 4: `.env` íŒŒì¼ ìƒì„± (ì‹¤ì œ í‚¤ ì…ë ¥)**

```bash
cp meetscribe/.env.example meetscribe/.env
# .env íŒŒì¼ì„ ì—ë””í„°ë¡œ ì—´ì–´ ì‹¤ì œ ê°’ ì…ë ¥
```

**Step 5: `meetscribe/config.py` ì‘ì„±**

```python
import os
from pathlib import Path
from dotenv import load_dotenv

load_dotenv(Path(__file__).parent / ".env")

OPENAI_API_KEY: str = os.environ["OPENAI_API_KEY"]
HF_TOKEN: str = os.environ["HF_TOKEN"]
WHISPER_MODEL: str = os.getenv("WHISPER_MODEL", "base")
LLM_MODEL: str = os.getenv("LLM_MODEL", "gpt-4o-mini")
VAULT_PATH: Path = Path(os.environ["VAULT_PATH"])
MEETINGS_FOLDER: str = os.getenv("MEETINGS_FOLDER", "10_Calendar/13_Meetings")
UPLOAD_DIR: Path = Path(__file__).parent / "uploads"

def validate_config() -> None:
    """ì•± ì‹œì‘ ì‹œ ì„¤ì •ê°’ ê²€ì¦"""
    if not VAULT_PATH.exists():
        raise RuntimeError(f"Vault ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VAULT_PATH}")
    meetings_path = VAULT_PATH / MEETINGS_FOLDER
    if not meetings_path.exists():
        meetings_path.mkdir(parents=True)
    UPLOAD_DIR.mkdir(exist_ok=True)
```

**Step 6: `meetscribe/tests/__init__.py` ìƒì„± (ë¹ˆ íŒŒì¼)**

**Step 7: ì˜ì¡´ì„± ì„¤ì¹˜**

```bash
cd meetscribe
pip install -r requirements.txt
```

Expected: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ (torch í¬í•¨, ìˆ˜ë¶„ ì†Œìš”)

**Step 8: ì„¤ì • ê²€ì¦ í…ŒìŠ¤íŠ¸**

```bash
python -c "from config import validate_config; validate_config(); print('ì„¤ì • OK')"
```

Expected: `ì„¤ì • OK`

**Step 9: Commit**

```bash
git init
git add requirements.txt .env.example config.py tests/ uploads/.gitkeep
echo ".env" >> .gitignore
echo "uploads/" >> .gitignore
echo "__pycache__/" >> .gitignore
git commit -m "feat: project setup - config and dependencies"
```

---

## Task 2: NoteBuilder ëª¨ë“ˆ (TDD ì„ í–‰)

NoteBuilderëŠ” ìˆœìˆ˜ í•¨ìˆ˜ë¼ í…ŒìŠ¤íŠ¸ê°€ ì‰½ë‹¤. ë¨¼ì € í…ŒìŠ¤íŠ¸ ì‘ì„±.

**Files:**
- Create: `meetscribe/tests/test_note_builder.py`
- Create: `meetscribe/pipeline/note_builder.py`

**Step 1: í…ŒìŠ¤íŠ¸ ì‘ì„±**

`meetscribe/tests/test_note_builder.py`:

```python
import pytest
from datetime import date
from pipeline.note_builder import build_meeting_note, build_transcript_note, NoteData

SAMPLE_DATA = NoteData(
    date=date(2026, 2, 18),
    title="ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·°",
    audio_filename="meeting.mp3",
    duration="05:30",
    speakers=["Speaker A", "Speaker B"],
    purpose="ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·° ë° ë°°í¬ ê³„íš ë…¼ì˜",
    discussion=["ECS V1.2 ì§„í–‰ë¥  75%", "í•´ìƒ ì‹œí—˜ ì¼ì • ì¡°ì •"],
    decisions=["ë°°í¬ì¼ 2026-02-25 í™•ì •"],
    action_items=["ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ (Speaker A, ~02/22)"],
    follow_up=["API íƒ€ì„ì•„ì›ƒ ì›ì¸ íŒŒì•… í•„ìš”"],
    transcript=[
        {"timestamp": "00:00:12", "speaker": "Speaker A", "text": "ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·° ì‹œì‘í•©ë‹ˆë‹¤."},
        {"timestamp": "00:01:05", "speaker": "Speaker B", "text": "ë¡œê·¸ì¸ ê¸°ëŠ¥ ì™„ë£ŒëìŠµë‹ˆë‹¤."},
    ],
)

def test_meeting_note_has_frontmatter():
    note = build_meeting_note(SAMPLE_DATA)
    assert note.startswith("---\n")
    assert "date: 2026-02-18" in note
    assert "type: meeting" in note
    assert "ai-transcribed" in note

def test_meeting_note_has_all_sections():
    note = build_meeting_note(SAMPLE_DATA)
    assert "## ëª©ì " in note
    assert "## ì£¼ìš” ë…¼ì˜" in note
    assert "## ê²°ì • ì‚¬í•­" in note
    assert "## Action Items" in note
    assert "## í›„ì† ì§ˆë¬¸" in note

def test_meeting_note_has_backlink_to_transcript():
    note = build_meeting_note(SAMPLE_DATA)
    assert "[[ì „ì‚¬] 2026-02-18 ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·°]]" in note

def test_meeting_note_action_items_are_checkboxes():
    note = build_meeting_note(SAMPLE_DATA)
    assert "- [ ] ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„" in note

def test_transcript_note_has_timestamps():
    note = build_transcript_note(SAMPLE_DATA)
    assert "**[00:00:12] Speaker A:**" in note
    assert "ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·° ì‹œì‘í•©ë‹ˆë‹¤." in note

def test_transcript_note_has_backlink_to_meeting():
    note = build_transcript_note(SAMPLE_DATA)
    assert "[[íšŒì˜] 2026-02-18 ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·°]]" in note

def test_filename_convention():
    from pipeline.note_builder import get_filenames
    meeting_fn, transcript_fn = get_filenames(SAMPLE_DATA)
    assert meeting_fn == "[íšŒì˜] 2026-02-18 ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·°.md"
    assert transcript_fn == "[ì „ì‚¬] 2026-02-18 ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·°.md"
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤íŒ¨ í™•ì¸)**

```bash
cd meetscribe
python -m pytest tests/test_note_builder.py -v
```

Expected: FAIL â€” `ModuleNotFoundError: pipeline.note_builder`

**Step 3: `meetscribe/pipeline/__init__.py` ìƒì„± (ë¹ˆ íŒŒì¼)**

**Step 4: `meetscribe/pipeline/note_builder.py` êµ¬í˜„**

```python
from dataclasses import dataclass, field
from datetime import date
from typing import Optional


@dataclass
class NoteData:
    date: date
    title: str
    audio_filename: str
    duration: str
    speakers: list[str]
    purpose: str
    discussion: list[str]
    decisions: list[str]
    action_items: list[str]
    follow_up: list[str]
    transcript: list[dict]  # {"timestamp": str, "speaker": str, "text": str}
    project: str = ""


def get_filenames(data: NoteData) -> tuple[str, str]:
    date_str = data.date.strftime("%Y-%m-%d")
    meeting = f"[íšŒì˜] {date_str} {data.title}.md"
    transcript = f"[ì „ì‚¬] {date_str} {data.title}.md"
    return meeting, transcript


def build_meeting_note(data: NoteData) -> str:
    date_str = data.date.strftime("%Y-%m-%d")
    _, transcript_filename = get_filenames(data)
    transcript_link = transcript_filename[:-3]  # .md ì œê±°

    participants_yaml = "\n".join(f"  - {s}" for s in data.speakers)
    discussion_items = "\n".join(f"- {d}" for d in data.discussion)
    decision_items = "\n".join(f"- {d}" for d in data.decisions)
    action_items = "\n".join(f"- [ ] {a}" for a in data.action_items)
    follow_up_items = "\n".join(f"- {f}" for f in data.follow_up)

    return f"""---
date: {date_str}
type: meeting
project: "{data.project}"
participants:
{participants_yaml}
tags:
  - meeting
  - ai-transcribed
audio: "{data.audio_filename}"
duration: "{data.duration}"
---

# [íšŒì˜] {date_str} {data.title}

> [!note] AI ìë™ ìƒì„±
> Whisper + LLMìœ¼ë¡œ ìë™ ìƒì„±. ì „ì²´ ì „ì‚¬: [[{transcript_link}]]

## ëª©ì 
{data.purpose}

## ì£¼ìš” ë…¼ì˜
{discussion_items}

## ê²°ì • ì‚¬í•­
{decision_items}

## Action Items
{action_items}

## í›„ì† ì§ˆë¬¸
{follow_up_items}
"""


def build_transcript_note(data: NoteData) -> str:
    date_str = data.date.strftime("%Y-%m-%d")
    meeting_filename, _ = get_filenames(data)
    meeting_link = meeting_filename[:-3]

    lines = "\n".join(
        f"**[{seg['timestamp']}] {seg['speaker']}:** {seg['text']}"
        for seg in data.transcript
    )

    return f"""---
date: {date_str}
type: meeting-transcript
tags:
  - transcript
---

# [ì „ì‚¬] {date_str} {data.title}

> ìš”ì•½: [[{meeting_link}]]

{lines}
"""
```

**Step 5: í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰ (í†µê³¼ í™•ì¸)**

```bash
python -m pytest tests/test_note_builder.py -v
```

Expected: 7ê°œ PASS

**Step 6: Commit**

```bash
git add pipeline/__init__.py pipeline/note_builder.py tests/test_note_builder.py
git commit -m "feat: note_builder - meeting and transcript markdown generation"
```

---

## Task 3: VaultWriter ëª¨ë“ˆ (TDD ì„ í–‰)

**Files:**
- Create: `meetscribe/tests/test_vault_writer.py`
- Create: `meetscribe/pipeline/vault_writer.py`

**Step 1: í…ŒìŠ¤íŠ¸ ì‘ì„±**

`meetscribe/tests/test_vault_writer.py`:

```python
import pytest
from pathlib import Path
from datetime import date
from pipeline.note_builder import NoteData, build_meeting_note, build_transcript_note, get_filenames
from pipeline.vault_writer import VaultWriter


SAMPLE_DATA = NoteData(
    date=date(2026, 2, 18),
    title="í…ŒìŠ¤íŠ¸ íšŒì˜",
    audio_filename="test.mp3",
    duration="01:00",
    speakers=["Speaker A"],
    purpose="í…ŒìŠ¤íŠ¸",
    discussion=["í•­ëª© 1"],
    decisions=["ê²°ì • 1"],
    action_items=["í•  ì¼ 1 (Speaker A, ~02/20)"],
    follow_up=[],
    transcript=[{"timestamp": "00:00:01", "speaker": "Speaker A", "text": "ì•ˆë…•í•˜ì„¸ìš”."}],
)


def test_saves_both_files(tmp_path):
    writer = VaultWriter(vault_path=tmp_path, meetings_folder="Meetings")
    meeting_note = build_meeting_note(SAMPLE_DATA)
    transcript_note = build_transcript_note(SAMPLE_DATA)
    meeting_fn, transcript_fn = get_filenames(SAMPLE_DATA)

    writer.save(SAMPLE_DATA, meeting_note, transcript_note)

    assert (tmp_path / "Meetings" / meeting_fn).exists()
    assert (tmp_path / "Meetings" / transcript_fn).exists()


def test_meeting_note_content_is_correct(tmp_path):
    writer = VaultWriter(vault_path=tmp_path, meetings_folder="Meetings")
    meeting_note = build_meeting_note(SAMPLE_DATA)
    transcript_note = build_transcript_note(SAMPLE_DATA)
    meeting_fn, _ = get_filenames(SAMPLE_DATA)

    writer.save(SAMPLE_DATA, meeting_note, transcript_note)

    content = (tmp_path / "Meetings" / meeting_fn).read_text(encoding="utf-8")
    assert "## ëª©ì " in content
    assert "í…ŒìŠ¤íŠ¸" in content


def test_returns_obsidian_uri(tmp_path):
    writer = VaultWriter(vault_path=tmp_path, meetings_folder="Meetings")
    meeting_note = build_meeting_note(SAMPLE_DATA)
    transcript_note = build_transcript_note(SAMPLE_DATA)

    result = writer.save(SAMPLE_DATA, meeting_note, transcript_note)

    assert result["meeting_uri"].startswith("obsidian://open")
    assert result["transcript_uri"].startswith("obsidian://open")


def test_creates_meetings_folder_if_missing(tmp_path):
    writer = VaultWriter(vault_path=tmp_path, meetings_folder="NewFolder/Meetings")
    meeting_note = build_meeting_note(SAMPLE_DATA)
    transcript_note = build_transcript_note(SAMPLE_DATA)

    writer.save(SAMPLE_DATA, meeting_note, transcript_note)

    assert (tmp_path / "NewFolder" / "Meetings").exists()
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤íŒ¨ í™•ì¸)**

```bash
python -m pytest tests/test_vault_writer.py -v
```

Expected: FAIL â€” `ModuleNotFoundError: pipeline.vault_writer`

**Step 3: `meetscribe/pipeline/vault_writer.py` êµ¬í˜„**

```python
from pathlib import Path
from urllib.parse import quote
from pipeline.note_builder import NoteData, get_filenames


class VaultWriter:
    def __init__(self, vault_path: Path, meetings_folder: str):
        self.vault_path = Path(vault_path)
        self.meetings_path = self.vault_path / meetings_folder

    def save(self, data: NoteData, meeting_note: str, transcript_note: str) -> dict:
        self.meetings_path.mkdir(parents=True, exist_ok=True)

        meeting_fn, transcript_fn = get_filenames(data)
        meeting_path = self.meetings_path / meeting_fn
        transcript_path = self.meetings_path / transcript_fn

        meeting_path.write_text(meeting_note, encoding="utf-8")
        transcript_path.write_text(transcript_note, encoding="utf-8")

        vault_name = self.vault_path.name
        meeting_uri = self._obsidian_uri(vault_name, meeting_fn)
        transcript_uri = self._obsidian_uri(vault_name, transcript_fn)

        return {
            "meeting_path": str(meeting_path),
            "transcript_path": str(transcript_path),
            "meeting_uri": meeting_uri,
            "transcript_uri": transcript_uri,
        }

    def _obsidian_uri(self, vault_name: str, filename: str) -> str:
        encoded_vault = quote(vault_name)
        encoded_file = quote(filename.replace(".md", ""))
        return f"obsidian://open?vault={encoded_vault}&file={encoded_file}"
```

**Step 4: í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰ (í†µê³¼ í™•ì¸)**

```bash
python -m pytest tests/test_vault_writer.py -v
```

Expected: 4ê°œ PASS

**Step 5: Commit**

```bash
git add pipeline/vault_writer.py tests/test_vault_writer.py
git commit -m "feat: vault_writer - save notes and return obsidian URIs"
```

---

## Task 4: Analyzer ëª¨ë“ˆ (LLM ë¶„ì„)

**Files:**
- Create: `meetscribe/tests/test_analyzer.py`
- Create: `meetscribe/pipeline/analyzer.py`

**Step 1: í…ŒìŠ¤íŠ¸ ì‘ì„± (íŒŒì‹± ë¡œì§ë§Œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸)**

`meetscribe/tests/test_analyzer.py`:

```python
import pytest
from pipeline.analyzer import parse_llm_response


SAMPLE_RESPONSE = """
PURPOSE: ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·° ë° 3ì›” ë°°í¬ ê³„íš ë…¼ì˜

DISCUSSION:
- ECS V1.2 ê°œë°œ ì§„í–‰ë¥  75% ì™„ë£Œ
- í•´ìƒ ì‹œí—˜ ì¼ì • ì¡°ì • ë…¼ì˜ (3/15 â†’ 3/20)
- Autopilot ì•Œê³ ë¦¬ì¦˜ íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

DECISIONS:
- í•´ìƒ ì‹œí—˜ 3ì›” 20ì¼ í™•ì •
- ì¶”ê°€ ë¬¸ì„œí™” ë§ˆê°: 3ì›” 5ì¼

ACTION_ITEMS:
- ECS V1.2 ì½”ë“œ ìœ ë‹› í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Speaker B, ~02/25)
- ì¶”ê°€ ë¬¸ì„œí™” ì‘ì„± ì‹œì‘ (Speaker A, ~02/28)

FOLLOW_UP:
- Autopilot ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ë²• ì¡°ì‚¬
"""


def test_parses_purpose():
    result = parse_llm_response(SAMPLE_RESPONSE)
    assert result["purpose"] == "ìŠ¤í”„ë¦°íŠ¸ ë¦¬ë·° ë° 3ì›” ë°°í¬ ê³„íš ë…¼ì˜"


def test_parses_discussion_items():
    result = parse_llm_response(SAMPLE_RESPONSE)
    assert len(result["discussion"]) == 3
    assert "ECS V1.2 ê°œë°œ ì§„í–‰ë¥  75% ì™„ë£Œ" in result["discussion"]


def test_parses_decisions():
    result = parse_llm_response(SAMPLE_RESPONSE)
    assert len(result["decisions"]) == 2


def test_parses_action_items():
    result = parse_llm_response(SAMPLE_RESPONSE)
    assert len(result["action_items"]) == 2
    assert "ECS V1.2 ì½”ë“œ ìœ ë‹› í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Speaker B, ~02/25)" in result["action_items"]


def test_parses_follow_up():
    result = parse_llm_response(SAMPLE_RESPONSE)
    assert len(result["follow_up"]) == 1


def test_handles_empty_sections():
    minimal = """
PURPOSE: ê°„ë‹¨í•œ ë¯¸íŒ…

DISCUSSION:
- í•­ëª© í•˜ë‚˜

DECISIONS:

ACTION_ITEMS:

FOLLOW_UP:
"""
    result = parse_llm_response(minimal)
    assert result["purpose"] == "ê°„ë‹¨í•œ ë¯¸íŒ…"
    assert result["decisions"] == []
    assert result["action_items"] == []
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤íŒ¨ í™•ì¸)**

```bash
python -m pytest tests/test_analyzer.py -v
```

Expected: FAIL

**Step 3: `meetscribe/pipeline/analyzer.py` êµ¬í˜„**

```python
import re
from openai import OpenAI
import config


SYSTEM_PROMPT = """ë‹¹ì‹ ì€ íšŒì˜ë¡ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ íšŒì˜ ì „ì‚¬ë³¸ì„ ë¶„ì„í•´ì„œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”.
ê° ì„¹ì…˜ì˜ í•­ëª©ì€ '- 'ë¡œ ì‹œì‘í•˜ëŠ” bullet pointë¡œ ì‘ì„±í•˜ì„¸ìš”.

PURPOSE: [íšŒì˜ ëª©ì  í•œ ì¤„]

DISCUSSION:
- [ì£¼ìš” ë…¼ì˜ í•­ëª© 1]
- [ì£¼ìš” ë…¼ì˜ í•­ëª© 2]

DECISIONS:
- [ê²°ì • ì‚¬í•­ 1]

ACTION_ITEMS:
- [í•  ì¼ ë‚´ìš© (ë‹´ë‹¹ì, ~ë§ˆê°ì¼)]

FOLLOW_UP:
- [í›„ì† ì§ˆë¬¸ì´ë‚˜ í™•ì¸ í•„ìš” ì‚¬í•­]

í•­ëª©ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì„¹ì…˜ì€ ë¹„ì›Œë‘ì„¸ìš”."""


def analyze_transcript(transcript_text: str) -> dict:
    """LLMìœ¼ë¡œ ì „ì‚¬ í…ìŠ¤íŠ¸ ë¶„ì„. configì—ì„œ API í‚¤ì™€ ëª¨ë¸ ë¡œë“œ."""
    client = OpenAI(api_key=config.OPENAI_API_KEY)
    response = client.chat.completions.create(
        model=config.LLM_MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"ë‹¤ìŒ íšŒì˜ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{transcript_text}"},
        ],
        temperature=0.3,
    )
    raw = response.choices[0].message.content
    return parse_llm_response(raw)


def parse_llm_response(response: str) -> dict:
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•´ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
    sections = {
        "purpose": "",
        "discussion": [],
        "decisions": [],
        "action_items": [],
        "follow_up": [],
    }

    # PURPOSE (ë‹¨ì¼ ë¼ì¸)
    purpose_match = re.search(r"PURPOSE:\s*(.+)", response)
    if purpose_match:
        sections["purpose"] = purpose_match.group(1).strip()

    # ì„¹ì…˜ë³„ bullet íŒŒì‹±
    section_map = {
        "DISCUSSION": "discussion",
        "DECISIONS": "decisions",
        "ACTION_ITEMS": "action_items",
        "FOLLOW_UP": "follow_up",
    }

    for section_key, dict_key in section_map.items():
        pattern = rf"{section_key}:\s*\n((?:- .+\n?)*)"
        match = re.search(pattern, response)
        if match:
            items = re.findall(r"- (.+)", match.group(1))
            sections[dict_key] = [item.strip() for item in items if item.strip()]

    return sections
```

**Step 4: í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰ (í†µê³¼ í™•ì¸)**

```bash
python -m pytest tests/test_analyzer.py -v
```

Expected: 7ê°œ PASS

**Step 5: Commit**

```bash
git add pipeline/analyzer.py tests/test_analyzer.py
git commit -m "feat: analyzer - LLM transcript analysis and response parsing"
```

---

## Task 5: Transcriber ëª¨ë“ˆ

> ì°¸ê³ : Whisperì™€ pyannoteëŠ” ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ê°€ ì–´ë µë‹¤. ì´ íƒœìŠ¤í¬ëŠ” êµ¬í˜„ í›„ ìˆ˜ë™ í†µí•© í…ŒìŠ¤íŠ¸.

**Files:**
- Create: `meetscribe/pipeline/transcriber.py`

**Step 1: `meetscribe/pipeline/transcriber.py` êµ¬í˜„**

```python
import os
import tempfile
from pathlib import Path
from typing import Optional
import torch

import config


def transcribe(audio_path: Path) -> dict:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ì‚¬. í™”ì ë¶„ë¦¬ í¬í•¨.
    Returns: {
        "segments": [{"timestamp": "HH:MM:SS", "speaker": "Speaker A", "text": "..."}],
        "full_text": str,
        "duration": str,
        "method": "local" | "api"
    }
    """
    try:
        return _transcribe_local(audio_path)
    except Exception as e:
        print(f"[Transcriber] ë¡œì»¬ Whisper ì‹¤íŒ¨: {e}. OpenAI APIë¡œ í´ë°±.")
        return _transcribe_api(audio_path)


def _transcribe_local(audio_path: Path) -> dict:
    """ë¡œì»¬ Whisper + pyannote í™”ì ë¶„ë¦¬"""
    import whisper
    from pyannote.audio import Pipeline

    # 1. Whisper ì „ì‚¬ (word-level timestamps)
    model = whisper.load_model(config.WHISPER_MODEL)
    result = model.transcribe(str(audio_path), word_timestamps=True, language="ko")

    # 2. pyannote í™”ì ë¶„ë¦¬
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization-3.1",
        use_auth_token=config.HF_TOKEN
    )
    if torch.cuda.is_available():
        pipeline = pipeline.to(torch.device("cuda"))

    diarization = pipeline(str(audio_path))

    # 3. Whisper ì„¸ê·¸ë¨¼íŠ¸ + í™”ì ë§¤í•‘
    segments = _merge_transcript_with_diarization(
        result["segments"], diarization
    )

    duration = _format_duration(result.get("duration", 0))
    full_text = " ".join(seg["text"] for seg in result["segments"])

    return {
        "segments": segments,
        "full_text": full_text,
        "duration": duration,
        "method": "local",
    }


def _transcribe_api(audio_path: Path) -> dict:
    """OpenAI Whisper API í´ë°± (í™”ì ë¶„ë¦¬ ì—†ìŒ, Speaker Aë§Œ ì‚¬ìš©)"""
    from openai import OpenAI

    client = OpenAI(api_key=config.OPENAI_API_KEY)

    with open(audio_path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            response_format="verbose_json",
            timestamp_granularities=["segment"],
            language="ko",
        )

    segments = []
    for seg in response.segments:
        ts = _format_duration(seg.start)
        segments.append({
            "timestamp": ts,
            "speaker": "Speaker A",
            "text": seg.text.strip(),
        })

    full_text = response.text
    duration = _format_duration(response.duration if hasattr(response, "duration") else 0)

    return {
        "segments": segments,
        "full_text": full_text,
        "duration": duration,
        "method": "api",
    }


def _merge_transcript_with_diarization(whisper_segments: list, diarization) -> list:
    """Whisper ì„¸ê·¸ë¨¼íŠ¸ì™€ pyannote í™”ì ë ˆì´ë¸” ë§¤í•‘"""
    # pyannote í™”ì IDë¥¼ Speaker A, B, ... ë¡œ ì •ê·œí™”
    speaker_map = {}
    label_counter = [0]

    def get_speaker_label(raw_label: str) -> str:
        if raw_label not in speaker_map:
            letter = chr(ord("A") + label_counter[0])
            speaker_map[raw_label] = f"Speaker {letter}"
            label_counter[0] += 1
        return speaker_map[raw_label]

    segments = []
    for seg in whisper_segments:
        start = seg["start"]
        # í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ë°œí™” ì¤‘ì¸ í™”ì ì°¾ê¸°
        speaker = "Speaker A"
        for turn, _, label in diarization.itertracks(yield_label=True):
            if turn.start <= start <= turn.end:
                speaker = get_speaker_label(label)
                break

        segments.append({
            "timestamp": _format_duration(start),
            "speaker": speaker,
            "text": seg["text"].strip(),
        })

    return segments


def _format_duration(seconds: float) -> str:
    """ì´ˆ â†’ HH:MM:SS í˜•ì‹"""
    seconds = int(seconds)
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    if h > 0:
        return f"{h:02d}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"
```

**Step 2: ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (ì§§ì€ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ)**

```bash
python -c "
from pathlib import Path
from pipeline.transcriber import transcribe
result = transcribe(Path('tests/sample.mp3'))  # ì§§ì€ í…ŒìŠ¤íŠ¸ íŒŒì¼ í•„ìš”
print('ë°©ë²•:', result['method'])
print('ê¸¸ì´:', result['duration'])
print('ì„¸ê·¸ë¨¼íŠ¸:', result['segments'][:2])
"
```

> ì°¸ê³ : `tests/sample.mp3` íŒŒì¼ì´ ì—†ìœ¼ë©´ ì§§ì€ í•œêµ­ì–´ ìŒì„± íŒŒì¼ì„ ì¤€ë¹„í•˜ê±°ë‚˜ ì´ ë‹¨ê³„ë¥¼ Task 8 í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ë¯¸ë£¸

**Step 3: Commit**

```bash
git add pipeline/transcriber.py
git commit -m "feat: transcriber - whisper local with pyannote diarization, API fallback"
```

---

## Task 6: FastAPI ë°±ì—”ë“œ

**Files:**
- Create: `meetscribe/main.py`

**Step 1: `meetscribe/main.py` êµ¬í˜„**

```python
import uuid
from pathlib import Path
from datetime import date
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse

import config
from config import validate_config
from pipeline.transcriber import transcribe
from pipeline.analyzer import analyze_transcript
from pipeline.note_builder import NoteData, build_meeting_note, build_transcript_note
from pipeline.vault_writer import VaultWriter

# ì§„í–‰ ìƒí™© ì €ì¥ (in-memory, ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ìš©)
job_status: dict[str, dict] = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    validate_config()
    yield


app = FastAPI(title="MeetScribe", lifespan=lifespan)
app.mount("/static", StaticFiles(directory="static"), name="static")


@app.get("/")
def index():
    return FileResponse("static/index.html")


@app.post("/upload")
async def upload(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    title: str = Form(""),
    project: str = Form(""),
):
    allowed = {".mp3", ".wav", ".m4a", ".mp4", ".webm", ".ogg"}
    suffix = Path(file.filename).suffix.lower()
    if suffix not in allowed:
        raise HTTPException(400, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {suffix}")

    job_id = str(uuid.uuid4())
    save_path = config.UPLOAD_DIR / f"{job_id}{suffix}"

    # íŒŒì¼ ì €ì¥
    content = await file.read()
    save_path.write_bytes(content)

    # ì œëª©ì´ ì—†ìœ¼ë©´ íŒŒì¼ëª… ì‚¬ìš©
    if not title:
        title = Path(file.filename).stem

    job_status[job_id] = {"status": "queued", "step": "", "result": None, "error": None}
    background_tasks.add_task(process_audio, job_id, save_path, title, project, file.filename)

    return {"job_id": job_id}


@app.get("/status/{job_id}")
def get_status(job_id: str):
    if job_id not in job_status:
        raise HTTPException(404, "Job not found")
    return job_status[job_id]


def process_audio(job_id: str, audio_path: Path, title: str, project: str, original_filename: str):
    """ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    try:
        # 1. ì „ì‚¬
        _update_status(job_id, "transcribing", "ì „ì‚¬ ì¤‘...")
        transcript_result = transcribe(audio_path)

        # 2. ë¶„ì„
        _update_status(job_id, "analyzing", "AI ë¶„ì„ ì¤‘...")
        analysis = analyze_transcript(transcript_result["full_text"])

        # 3. ë…¸íŠ¸ ìƒì„±
        _update_status(job_id, "building", "ë…¸íŠ¸ ìƒì„± ì¤‘...")
        today = date.today()
        speakers = list({seg["speaker"] for seg in transcript_result["segments"]})
        speakers.sort()

        note_data = NoteData(
            date=today,
            title=title,
            audio_filename=original_filename,
            duration=transcript_result["duration"],
            speakers=speakers,
            purpose=analysis["purpose"],
            discussion=analysis["discussion"],
            decisions=analysis["decisions"],
            action_items=analysis["action_items"],
            follow_up=analysis["follow_up"],
            transcript=transcript_result["segments"],
            project=project,
        )

        meeting_note = build_meeting_note(note_data)
        transcript_note = build_transcript_note(note_data)

        # 4. Vault ì €ì¥
        _update_status(job_id, "saving", "Vaultì— ì €ì¥ ì¤‘...")
        writer = VaultWriter(
            vault_path=config.VAULT_PATH,
            meetings_folder=config.MEETINGS_FOLDER,
        )
        result = writer.save(note_data, meeting_note, transcript_note)

        # ì™„ë£Œ
        job_status[job_id] = {
            "status": "done",
            "step": "ì™„ë£Œ",
            "result": result,
            "error": None,
        }

    except Exception as e:
        job_status[job_id] = {
            "status": "error",
            "step": "ì˜¤ë¥˜ ë°œìƒ",
            "result": None,
            "error": str(e),
        }
    finally:
        # ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬
        if audio_path.exists():
            audio_path.unlink()


def _update_status(job_id: str, status: str, step: str):
    job_status[job_id] = {
        "status": status,
        "step": step,
        "result": None,
        "error": None,
    }
```

**Step 2: ì•± ê¸°ë™ í…ŒìŠ¤íŠ¸**

```bash
cd meetscribe
uvicorn main:app --reload --port 8765
```

Expected: `INFO: Application startup complete.` (ì—ëŸ¬ ì—†ì´)

**Step 3: API í—¬ìŠ¤ì²´í¬**

```bash
curl http://localhost:8765/
```

Expected: HTML ì‘ë‹µ (index.htmlì´ ì•„ì§ ì—†ìœ¼ë©´ 404 â†’ Task 7 í›„ ë‹¤ì‹œ í™•ì¸)

**Step 4: Commit**

```bash
git add main.py
git commit -m "feat: fastapi backend - upload, status polling, background processing pipeline"
```

---

## Task 7: ì›¹ í”„ë¡ íŠ¸ì—”ë“œ

**Files:**
- Create: `meetscribe/static/index.html`

**Step 1: `meetscribe/static/index.html` êµ¬í˜„**

```html
<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MeetScribe</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      background: #1a1a2e;
      color: #e0e0e0;
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .container {
      width: 480px;
      background: #16213e;
      border-radius: 16px;
      padding: 32px;
      box-shadow: 0 8px 32px rgba(0,0,0,0.4);
    }
    h1 { font-size: 1.6rem; margin-bottom: 8px; color: #7c83fd; }
    .subtitle { font-size: 0.85rem; color: #888; margin-bottom: 24px; }
    #drop-zone {
      border: 2px dashed #7c83fd44;
      border-radius: 12px;
      padding: 32px;
      text-align: center;
      cursor: pointer;
      transition: border-color 0.2s, background 0.2s;
      margin-bottom: 20px;
    }
    #drop-zone.dragover {
      border-color: #7c83fd;
      background: #7c83fd11;
    }
    #drop-zone .icon { font-size: 2rem; margin-bottom: 8px; }
    #drop-zone .hint { font-size: 0.8rem; color: #888; margin-top: 4px; }
    #file-name { font-size: 0.85rem; color: #7c83fd; margin-top: 8px; }
    input[type="file"] { display: none; }
    .field { margin-bottom: 16px; }
    label { display: block; font-size: 0.8rem; color: #aaa; margin-bottom: 6px; }
    input[type="text"] {
      width: 100%;
      padding: 10px 14px;
      background: #0f3460;
      border: 1px solid #ffffff11;
      border-radius: 8px;
      color: #e0e0e0;
      font-size: 0.9rem;
      outline: none;
    }
    input[type="text"]:focus { border-color: #7c83fd; }
    button#submit {
      width: 100%;
      padding: 14px;
      background: #7c83fd;
      color: white;
      border: none;
      border-radius: 10px;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s;
      margin-top: 4px;
    }
    button#submit:hover { background: #6a71e0; }
    button#submit:disabled { background: #444; cursor: not-allowed; }
    #progress { margin-top: 24px; display: none; }
    .step {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 8px 0;
      font-size: 0.9rem;
      color: #888;
    }
    .step.done { color: #4caf50; }
    .step.active { color: #7c83fd; }
    .step-icon { width: 20px; text-align: center; }
    #result { margin-top: 20px; display: none; }
    .result-card {
      background: #0f3460;
      border-radius: 10px;
      padding: 16px;
    }
    .result-card h3 { font-size: 0.9rem; color: #aaa; margin-bottom: 10px; }
    .obsidian-btn {
      display: block;
      width: 100%;
      padding: 10px;
      background: #7c3aed;
      color: white;
      border: none;
      border-radius: 8px;
      font-size: 0.9rem;
      cursor: pointer;
      text-align: center;
      text-decoration: none;
      margin-bottom: 8px;
      transition: background 0.2s;
    }
    .obsidian-btn:hover { background: #6d28d9; }
    #error-msg {
      background: #3f0000;
      border: 1px solid #ff4444;
      border-radius: 8px;
      padding: 12px;
      margin-top: 16px;
      font-size: 0.85rem;
      color: #ff8080;
      display: none;
    }
  </style>
</head>
<body>
<div class="container">
  <h1>MeetScribe</h1>
  <p class="subtitle">íšŒì˜ ë…¹ìŒ â†’ ìë™ ì „ì‚¬ â†’ Obsidian ë…¸íŠ¸</p>

  <div id="drop-zone" onclick="document.getElementById('file-input').click()">
    <div class="icon">ğŸ™ï¸</div>
    <div>íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì„¸ìš”</div>
    <div class="hint">mp3 / wav / m4a / mp4</div>
    <div id="file-name"></div>
  </div>
  <input type="file" id="file-input" accept=".mp3,.wav,.m4a,.mp4,.webm,.ogg">

  <div class="field">
    <label>íšŒì˜ ì œëª©</label>
    <input type="text" id="title" placeholder="ìë™ìœ¼ë¡œ íŒŒì¼ëª… ì‚¬ìš©">
  </div>
  <div class="field">
    <label>í”„ë¡œì íŠ¸ (ì„ íƒ)</label>
    <input type="text" id="project" placeholder="ì˜ˆ: [[USV Project Dashboard]]">
  </div>

  <button id="submit" disabled>ë¶„ì„ ì‹œì‘</button>

  <div id="progress">
    <div class="step" id="step-upload"><span class="step-icon">â¬œ</span>ì—…ë¡œë“œ</div>
    <div class="step" id="step-transcribe"><span class="step-icon">â¬œ</span>ì „ì‚¬ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)</div>
    <div class="step" id="step-analyze"><span class="step-icon">â¬œ</span>AI ë¶„ì„</div>
    <div class="step" id="step-save"><span class="step-icon">â¬œ</span>Vault ì €ì¥</div>
  </div>

  <div id="error-msg"></div>

  <div id="result">
    <div class="result-card">
      <h3>âœ… ì™„ë£Œ! Obsidianì—ì„œ ì—´ê¸°:</h3>
      <a id="open-meeting" class="obsidian-btn" href="#">ğŸ“ íšŒì˜ ë…¸íŠ¸ ì—´ê¸°</a>
      <a id="open-transcript" class="obsidian-btn" href="#">ğŸ“„ ì „ì‚¬ ë…¸íŠ¸ ì—´ê¸°</a>
    </div>
  </div>
</div>

<script>
  const dropZone = document.getElementById('drop-zone');
  const fileInput = document.getElementById('file-input');
  const submitBtn = document.getElementById('submit');
  const fileNameEl = document.getElementById('file-name');
  let selectedFile = null;

  // ë“œë˜ê·¸ì•¤ë“œë¡­
  dropZone.addEventListener('dragover', e => { e.preventDefault(); dropZone.classList.add('dragover'); });
  dropZone.addEventListener('dragleave', () => dropZone.classList.remove('dragover'));
  dropZone.addEventListener('drop', e => {
    e.preventDefault();
    dropZone.classList.remove('dragover');
    const file = e.dataTransfer.files[0];
    if (file) setFile(file);
  });
  fileInput.addEventListener('change', () => {
    if (fileInput.files[0]) setFile(fileInput.files[0]);
  });

  function setFile(file) {
    selectedFile = file;
    fileNameEl.textContent = file.name;
    submitBtn.disabled = false;
  }

  // ì—…ë¡œë“œ & í´ë§
  submitBtn.addEventListener('click', async () => {
    if (!selectedFile) return;

    submitBtn.disabled = true;
    document.getElementById('progress').style.display = 'block';
    document.getElementById('result').style.display = 'none';
    document.getElementById('error-msg').style.display = 'none';

    setStep('step-upload', 'active');

    const formData = new FormData();
    formData.append('file', selectedFile);
    formData.append('title', document.getElementById('title').value);
    formData.append('project', document.getElementById('project').value);

    let jobId;
    try {
      const res = await fetch('/upload', { method: 'POST', body: formData });
      const data = await res.json();
      if (!res.ok) throw new Error(data.detail || 'ì—…ë¡œë“œ ì‹¤íŒ¨');
      jobId = data.job_id;
    } catch (e) {
      showError(e.message);
      submitBtn.disabled = false;
      return;
    }

    setStep('step-upload', 'done');
    pollStatus(jobId);
  });

  async function pollStatus(jobId) {
    const interval = setInterval(async () => {
      try {
        const res = await fetch(`/status/${jobId}`);
        const data = await res.json();

        if (data.status === 'transcribing') {
          setStep('step-transcribe', 'active');
        } else if (data.status === 'analyzing') {
          setStep('step-transcribe', 'done');
          setStep('step-analyze', 'active');
        } else if (data.status === 'saving' || data.status === 'building') {
          setStep('step-analyze', 'done');
          setStep('step-save', 'active');
        } else if (data.status === 'done') {
          clearInterval(interval);
          setStep('step-save', 'done');
          showResult(data.result);
          submitBtn.disabled = false;
        } else if (data.status === 'error') {
          clearInterval(interval);
          showError(data.error);
          submitBtn.disabled = false;
        }
      } catch (e) {
        clearInterval(interval);
        showError('ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: ' + e.message);
        submitBtn.disabled = false;
      }
    }, 2000);
  }

  function setStep(id, state) {
    const el = document.getElementById(id);
    el.className = `step ${state}`;
    const icon = el.querySelector('.step-icon');
    icon.textContent = state === 'done' ? 'âœ…' : state === 'active' ? 'â³' : 'â¬œ';
  }

  function showResult(result) {
    document.getElementById('result').style.display = 'block';
    document.getElementById('open-meeting').href = result.meeting_uri;
    document.getElementById('open-transcript').href = result.transcript_uri;
  }

  function showError(msg) {
    const el = document.getElementById('error-msg');
    el.textContent = 'ì˜¤ë¥˜: ' + msg;
    el.style.display = 'block';
  }
</script>
</body>
</html>
```

**Step 2: ê¸°ë™ í›„ UI í™•ì¸**

```bash
uvicorn main:app --reload --port 8765
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8765` ì—´ì–´ì„œ:
- [ ] ë“œë˜ê·¸ì•¤ë“œë¡­ ì˜ì—­ í‘œì‹œ
- [ ] íŒŒì¼ ì„ íƒ ì‹œ ë²„íŠ¼ í™œì„±í™”
- [ ] ì§„í–‰ ë‹¨ê³„ í‘œì‹œ

**Step 3: Commit**

```bash
git add static/index.html
git commit -m "feat: web UI - drag and drop upload with progress polling and obsidian URIs"
```

---

## Task 8: í†µí•© í…ŒìŠ¤íŠ¸

**Files:**
- Create: `meetscribe/tests/test_integration.py`
- Create: `meetscribe/tests/generate_test_audio.py`

**Step 1: í…ŒìŠ¤íŠ¸ìš© ì§§ì€ ì˜¤ë””ì˜¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸**

`meetscribe/tests/generate_test_audio.py`:

```python
"""
í…ŒìŠ¤íŠ¸ìš© ì§§ì€ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± (gTTS ì‚¬ìš©)
pip install gtts
"""
from pathlib import Path

def generate():
    try:
        from gtts import gTTS
        text = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì•ˆê±´ì€ í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ì…ë‹ˆë‹¤. ë„¤, ì˜ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        tts = gTTS(text=text, lang='ko')
        out = Path(__file__).parent / "sample.mp3"
        tts.save(str(out))
        print(f"ìƒì„±ë¨: {out}")
        return out
    except ImportError:
        print("pip install gtts ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„")
        return None

if __name__ == "__main__":
    generate()
```

**Step 2: í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±**

```bash
pip install gtts
python tests/generate_test_audio.py
```

Expected: `tests/sample.mp3` ìƒì„±

**Step 3: `meetscribe/tests/test_integration.py` ì‘ì„±**

```python
"""
í†µí•© í…ŒìŠ¤íŠ¸: ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
ì‹¤í–‰: pytest tests/test_integration.py -v -s
"""
import pytest
from pathlib import Path
import tempfile

SAMPLE_AUDIO = Path(__file__).parent / "sample.mp3"


@pytest.fixture
def tmp_vault(tmp_path):
    meetings = tmp_path / "10_Calendar" / "13_Meetings"
    meetings.mkdir(parents=True)
    return tmp_path


@pytest.mark.skipif(not SAMPLE_AUDIO.exists(), reason="sample.mp3 ì—†ìŒ")
def test_full_pipeline(tmp_vault, monkeypatch):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    import config
    monkeypatch.setattr(config, "VAULT_PATH", tmp_vault)
    monkeypatch.setattr(config, "MEETINGS_FOLDER", "10_Calendar/13_Meetings")

    from pipeline.transcriber import transcribe
    from pipeline.analyzer import analyze_transcript
    from pipeline.note_builder import NoteData, build_meeting_note, build_transcript_note
    from pipeline.vault_writer import VaultWriter
    from datetime import date

    # ì „ì‚¬
    result = transcribe(SAMPLE_AUDIO)
    assert result["segments"]
    assert result["duration"]

    # ë¶„ì„
    analysis = analyze_transcript(result["full_text"])
    assert isinstance(analysis["purpose"], str)

    # ë…¸íŠ¸ ìƒì„±
    note_data = NoteData(
        date=date.today(),
        title="í†µí•© í…ŒìŠ¤íŠ¸",
        audio_filename="sample.mp3",
        duration=result["duration"],
        speakers=list({s["speaker"] for s in result["segments"]}),
        purpose=analysis["purpose"],
        discussion=analysis["discussion"],
        decisions=analysis["decisions"],
        action_items=analysis["action_items"],
        follow_up=analysis["follow_up"],
        transcript=result["segments"],
    )

    meeting_note = build_meeting_note(note_data)
    transcript_note = build_transcript_note(note_data)

    # ì €ì¥
    writer = VaultWriter(tmp_vault, "10_Calendar/13_Meetings")
    save_result = writer.save(note_data, meeting_note, transcript_note)

    assert Path(save_result["meeting_path"]).exists()
    assert Path(save_result["transcript_path"]).exists()
    assert "obsidian://open" in save_result["meeting_uri"]

    print("\n=== ìƒì„±ëœ íšŒì˜ ë…¸íŠ¸ ===")
    print(Path(save_result["meeting_path"]).read_text(encoding="utf-8"))
```

**Step 4: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì „ì²´ ì‹¤í–‰**

```bash
python -m pytest tests/test_note_builder.py tests/test_vault_writer.py tests/test_analyzer.py -v
```

Expected: 18ê°œ PASS

**Step 5: í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰**

```bash
python -m pytest tests/test_integration.py -v -s
```

Expected: PASS (ì¸í„°ë„· ì—°ê²° í•„ìš”, Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í¬í•¨)

**Step 6: ìµœì¢… Commit**

```bash
git add tests/test_integration.py tests/generate_test_audio.py tests/sample.mp3
git commit -m "test: integration test for full pipeline with sample audio"
```

---

## Task 9: ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ & README

**Files:**
- Create: `meetscribe/run.bat` (Windows)
- Create: `meetscribe/README.md`

**Step 1: `meetscribe/run.bat` ì‘ì„±**

```bat
@echo off
echo MeetScribe ì‹œì‘ ì¤‘...
cd /d "%~dp0"
uvicorn main:app --host 0.0.0.0 --port 8765
```

**Step 2: `meetscribe/README.md` ì‘ì„±**

````markdown
# MeetScribe

íšŒì˜ ë…¹ìŒ â†’ Whisper ì „ì‚¬ â†’ GPT ë¶„ì„ â†’ Obsidian ë…¸íŠ¸ ìë™ ìƒì„±

## ì„¤ì¹˜

```bash
pip install -r requirements.txt
cp .env.example .env
# .env íŒŒì¼ì— API í‚¤ ì…ë ¥
```

## HuggingFace ì„¤ì • (í™”ì ë¶„ë¦¬ìš©)
1. https://hf.co/pyannote/speaker-diarization-3.1 Accept
2. https://hf.co/pyannote/segmentation-3.0 Accept
3. https://hf.co/settings/tokens ì—ì„œ í† í° ìƒì„± â†’ .envì— HF_TOKEN ì…ë ¥

## ì‹¤í–‰

```bash
uvicorn main:app --port 8765
# ë˜ëŠ”
run.bat
```

ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8765 ì—´ê¸°

## í…ŒìŠ¤íŠ¸

```bash
pytest tests/ -v
```
````

**Step 3: ìµœì¢… Commit**

```bash
git add run.bat README.md
git commit -m "docs: add run script and README"
```

---

## ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `python -m pytest tests/ -v` â€” 18ê°œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ PASS
- [ ] `uvicorn main:app --port 8765` â€” ì•± ì •ìƒ ê¸°ë™
- [ ] ë¸Œë¼ìš°ì €ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ â†’ ì§„í–‰ ìƒí™© í‘œì‹œ â†’ Obsidian ì—´ê¸° ë²„íŠ¼
- [ ] Obsidian Vault `10_Calendar/13_Meetings/` ì— [íšŒì˜]/[ì „ì‚¬] íŒŒì¼ ìƒì„± í™•ì¸
- [ ] ê¸°ì¡´ Meeting Note í…œí”Œë¦¿ê³¼ í˜•ì‹ í˜¸í™˜ í™•ì¸
